{"cells":[{"metadata":{},"cell_type":"markdown","source":"## Desclaimer\nI am in a beginer level currently.\nIt should be noted that I have trained this notebook on previous 2019 version notebook and then copy and pasted the codes from there in this one as I found only that method possible for me to use the extract_feature function(in official BIRT repo on github) to get the embeddings.\nSo it would nice to understand by just reading and for more understanding you can also run it in your old versioned notebook.","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"### Brief Discription of the model\nI have used the pretrained BERT model to get the embeddings for texts in each row.\nThen I have extracted the embeddings for nouns and pronouns from there and combined it with the label column to get a separate data frame containing emb_P,emb_A,emb_B and labels.\nNow it is just a problem of multiclass classification.\nFor the sake of simplicity I have done that by fitting logistic regression model from scikit learn.\nAnd finally did the prediction.\nSince testdata was very large I have formed a loop and passed actually the small sliced form of that testdata and did the prediction.\nI have got a private score of 0.51952 finally.","execution_count":null},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os\nimport zipfile\nimport sys\nimport time","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Downloding weights and configuration","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!wget https://storage.googleapis.com/bert_models/2018_10_18/uncased_L-12_H-768_A-12.zip\nwith zipfile.ZipFile(\"uncased_L-12_H-768_A-12.zip\",\"r\") as zip_ref:\n    zip_ref.extractall()\n!ls 'uncased_L-12_H-768_A-12'","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"We will use some of the important scripts from the bert repo which you can find here(https://github.com/google-research/bert)","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!wget https://raw.githubusercontent.com/google-research/bert/master/modeling.py \n!wget https://raw.githubusercontent.com/google-research/bert/master/extract_features.py \n!wget https://raw.githubusercontent.com/google-research/bert/master/tokenization.py","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import modeling\nimport extract_features\nimport tokenization\nimport tensorflow as tf","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Finally downloading the data from the git repo","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"!wget https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-development.tsv\n!wget https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-validation.tsv\n!wget https://raw.githubusercontent.com/google-research-datasets/gap-coreference/master/gap-test.tsv\n!ls","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Next, we feed BERT the data from these three files. For each line, we want to obtain contextual embeddings for the 3 target words (A, B, Pronoun). Here are some helper functions to keep track of the offsets of the target words.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def compute_offset_no_spaces(text, offset):\n\tcount = 0\n\tfor pos in range(offset):\n\t\tif text[pos] != \" \": count +=1\n\treturn count\n\ndef count_chars_no_special(text):\n\tcount = 0\n\tspecial_char_list = [\"#\"]\n\tfor pos in range(len(text)):\n\t\tif text[pos] not in special_char_list: count +=1\n\treturn count\n\ndef count_length_no_special(text):\n\tcount = 0\n\tspecial_char_list = [\"#\", \" \"]\n\tfor pos in range(len(text)):\n\t\tif text[pos] not in special_char_list: count +=1\n\treturn count","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"The following method takes the data from a file, passes it through BERT to obtain contextual embeddings for the target words, then returns these embeddings in the emb DataFrame. Below, we will use it 3 times, once for each of the files gap-test, gap-development, gap-validation.","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_bert(data):\n\t'''\n\tRuns a forward propagation of BERT on input text, extracting contextual word embeddings\n\tInput: data, a pandas DataFrame containing the information in one of the GAP files\n\n\tOutput: emb, a pandas DataFrame containing contextual embeddings for the words A, B and Pronoun. Each embedding is a numpy array of shape (768)\n\tcolumns: \"emb_A\": the embedding for word A\n\t         \"emb_B\": the embedding for word B\n\t         \"emb_P\": the embedding for the pronoun\n\t         \"label\": the answer to the coreference problem: \"A\", \"B\" or \"NEITHER\"\n\t'''\n    # From the current file, take the text only, and write it in a file which will be passed to BERT\n\ttext = data[\"Text\"]\n\ttext.to_csv(\"input.txt\", index = False, header = False)\n\n    # The script extract_features.py runs forward propagation through BERT, and writes the output in the file output.jsonl\n   \n\tos.system(\"python3 extract_features.py \\\n\t  --input_file=input.txt \\\n\t  --output_file=output.jsonl \\\n\t  --vocab_file=uncased_L-12_H-768_A-12/vocab.txt \\\n\t  --bert_config_file=uncased_L-12_H-768_A-12/bert_config.json \\\n\t  --init_checkpoint=uncased_L-12_H-768_A-12/bert_model.ckpt \\\n\t  --layers=-1 \\\n\t  --max_seq_length=256 \\\n\t  --batch_size=8\")\n\n\tbert_output = pd.read_json(\"output.jsonl\", lines = True)\n\n\tos.system(\"rm output.jsonl\")\n\tos.system(\"rm input.txt\")\n\n\tindex = data.index\n\tcolumns = [\"emb_A\", \"emb_B\", \"emb_P\", \"label\"]\n\temb = pd.DataFrame(index = index, columns = columns)\n\temb.index.name = \"ID\"\n\n\tfor i in range(len(data)): # For each line in the data file\n\t\t# get the words A, B, Pronoun. Convert them to lower case, since we're using the uncased version of BERT\n\t\tP = data.loc[i,\"Pronoun\"].lower()\n\t\tA = data.loc[i,\"A\"].lower()\n\t\tB = data.loc[i,\"B\"].lower()\n\n\t\t# For each word, find the offset not counting spaces. This is necessary for comparison with the output of BERT\n\t\tP_offset = compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"Pronoun-offset\"])\n\t\tA_offset = compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"A-offset\"])\n\t\tB_offset = compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"B-offset\"])\n\t\t# Figure out the length of A, B, not counting spaces or special characters\n\t\tA_length = count_length_no_special(A)\n\t\tB_length = count_length_no_special(B)\n\n\t\t# Initialize embeddings with zeros\n\t\temb_A = np.zeros(768)\n\t\temb_B = np.zeros(768)\n\t\temb_P = np.zeros(768)\n\n\t\t# Initialize counts\n\t\tcount_chars = 0\n\t\tcnt_A, cnt_B, cnt_P = 0, 0, 0\n\n\t\tfeatures = pd.DataFrame(bert_output.loc[i,\"features\"]) # Get the BERT embeddings for the current line in the data file\n\t\tfor j in range(2,len(features)):  # Iterate over the BERT tokens for the current line; we skip over the first 2 tokens, which don't correspond to words\n\t\t\ttoken = features.loc[j,\"token\"]\n\n\t\t\t# See if the character count until the current token matches the offset of any of the 3 target words\n\t\t\tif count_chars  == P_offset: \n\t\t\t\t# print(token)\n\t\t\t\temb_P += np.array(features.loc[j,\"layers\"][0]['values'])\n\t\t\t\tcnt_P += 1\n\t\t\tif count_chars in range(A_offset, A_offset + A_length): \n\t\t\t\t# print(token)\n\t\t\t\temb_A += np.array(features.loc[j,\"layers\"][0]['values'])\n\t\t\t\tcnt_A +=1\n\t\t\tif count_chars in range(B_offset, B_offset + B_length): \n\t\t\t\t# print(token)\n\t\t\t\temb_B += np.array(features.loc[j,\"layers\"][0]['values'])\n\t\t\t\tcnt_B +=1\t\t\t\t\t\t\t\t\n\t\t\t# Update the character count\n\t\t\tcount_chars += count_length_no_special(token)\n\t\t# Taking the average between tokens in the span of A or B, so divide the current value by the count\t\n\t\temb_A /= cnt_A\n\t\temb_B /= cnt_B\n\n\t\t# Work out the label of the current piece of text\n\t\tlabel = \"Neither\"\n\t\tif (data.loc[i,\"A-coref\"] == True):\n\t\t\tlabel = \"A\"\n\t\tif (data.loc[i,\"B-coref\"] == True):\n\t\t\tlabel = \"B\"\n\n\t\t# Put everything together in emb\n\t\temb.iloc[i] = [emb_A, emb_B, emb_P, label]\n\n\treturn emb","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"markdown","source":"Read the two GAP files, pass them through BERT.","execution_count":null},{"metadata":{"trusted":true,"collapsed":true},"cell_type":"code","source":"validation_data = pd.read_csv(\"gap-validation.tsv\", sep = '\\t')\nvalidation_emb = run_bert(validation_data)\n\ndevelopment_data = pd.read_csv(\"gap-development.tsv\", sep = '\\t')\ndevelopment_emb = run_bert(development_data)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Handling missing values..","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tqdm import tqdm\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def featurize(embedding_df):\n    \n    pronoun_embs, a_embs, b_embs, labels = [], [], [], []\n    \n    for i in tqdm(range(len(embedding_df))):\n        \n        pronoun_embs.append(embedding_df.loc[i, \"emb_P\"])\n        a_embs.append(embedding_df.loc[i, \"emb_A\"])\n        b_embs.append(embedding_df.loc[i, \"emb_B\"])\n\n        label_map = {'A': 0, 'B': 1, 'Neither': 2}\n        labels.append(label_map[embedding_df.loc[i, \"label\"]])\n\n    \n    a_embs = np.asarray(a_embs).astype('float')\n    b_embs = np.asarray(b_embs).astype('float') \n    pronoun_embs = np.asarray(pronoun_embs).astype('float')\n    \n    return np.concatenate([a_embs, b_embs, pronoun_embs], axis=1), np.asarray(labels)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train, y_train = featurize(pd.concat([validation_emb, development_emb]).sort_index().reset_index())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"X_train = my_imputer.fit_transform(X_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit = LogisticRegression(C=0.0075, class_weight=None, dual=False, fit_intercept=True,\n          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n          n_jobs=4, penalty='l2', random_state=42, solver='lbfgs',\n          tol=0.0001, verbose=0, warm_start=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"logit.fit(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Saving the learned weights","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"import pickle\nfilename = 'finalized_model.sav'\npickle.dump(logit, open(filename, 'wb')","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Moving for prediction part","execution_count":null},{"metadata":{},"cell_type":"markdown","source":"Handling missing values","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.impute import SimpleImputer\nmy_imputer = SimpleImputer()","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modifying featurise function for prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def featurizepred(embedding_df):\n    \n    pronoun_embs, a_embs, b_embs = [], [], []\n    \n    for i in tqdm(range(len(embedding_df))):\n        \n        pronoun_embs.append(embedding_df.loc[10000+i, \"emb_P\"])\n        a_embs.append(embedding_df.loc[10000+i, \"emb_A\"])\n        b_embs.append(embedding_df.loc[10000+i, \"emb_B\"])\n\n#         label_map = {'A': 0, 'B': 1, 'Neither': 2}\n#         labels.append(label_map[embedding_df.loc[i, \"label\"]])\n\n    \n    a_embs = np.asarray(a_embs).astype('float')\n    b_embs = np.asarray(b_embs).astype('float') \n    pronoun_embs = np.asarray(pronoun_embs).astype('float')\n    \n    return np.concatenate([a_embs, b_embs, pronoun_embs], axis=1)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Modifying the run-bert function for prediction","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"def run_bertpred(data):\n\t'''\n\tRuns a forward propagation of BERT on input text, extracting contextual word embeddings\n\tInput: data, a pandas DataFrame containing the information in one of the GAP files\n\n\tOutput: emb, a pandas DataFrame containing contextual embeddings for the words A, B and Pronoun. Each embedding is a numpy array of shape (768)\n\tcolumns: \"emb_A\": the embedding for word A\n\t         \"emb_B\": the embedding for word B\n\t         \"emb_P\": the embedding for the pronoun\n\t         \"label\": the answer to the coreference problem: \"A\", \"B\" or \"NEITHER\"\n\t'''\n    # From the current file, take the text only, and write it in a file which will be passed to BERT\n\ttext = data[\"Text\"]\n\ttext.to_csv(\"input.txt\", index = False, header = False)\n\n    # The script extract_features.py runs forward propagation through BERT, and writes the output in the file output.jsonl\n    # I'm lazy, so I'm only saving the output of the last layer. Feel free to change --layers = -1 to save the output of other layers.\n\tos.system(\"python3 extract_features.py \\\n\t  --input_file=input.txt \\\n\t  --output_file=output.jsonl \\\n\t  --vocab_file=uncased_L-12_H-768_A-12/vocab.txt \\\n\t  --bert_config_file=uncased_L-12_H-768_A-12/bert_config.json \\\n\t  --init_checkpoint=uncased_L-12_H-768_A-12/bert_model.ckpt \\\n\t  --layers=-1 \\\n\t  --max_seq_length=256 \\\n\t  --batch_size=8\")\n\n\tbert_output = pd.read_json(\"output.jsonl\", lines = True)\n\n\tos.system(\"rm output.jsonl\")\n\tos.system(\"rm input.txt\")\n\n\tindex = data.index\n\tcolumns = [\"emb_A\", \"emb_B\", \"emb_P\"]\n\temb = pd.DataFrame(index = index, columns = columns)\n\temb.index.name = \"ID\"\n\n\tfor i in range(len(data)): # For each line in the data file\n\t\t# get the words A, B, Pronoun. Convert them to lower case, since we're using the uncased version of BERT\n\t\tP = data.loc[i,\"Pronoun\"].lower()\n\t\tA = data.loc[i,\"A\"].lower()\n\t\tB = data.loc[i,\"B\"].lower()\n\n\t\t# For each word, find the offset not counting spaces. This is necessary for comparison with the output of BERT\n\t\tP_offset = compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"Pronoun-offset\"])\n\t\tA_offset = compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"A-offset\"])\n\t\tB_offset = compute_offset_no_spaces(data.loc[i,\"Text\"], data.loc[i,\"B-offset\"])\n\t\t# Figure out the length of A, B, not counting spaces or special characters\n\t\tA_length = count_length_no_special(A)\n\t\tB_length = count_length_no_special(B)\n\n\t\t# Initialize embeddings with zeros\n\t\temb_A = np.zeros(768)\n\t\temb_B = np.zeros(768)\n\t\temb_P = np.zeros(768)\n\n\t\t# Initialize counts\n\t\tcount_chars = 0\n\t\tcnt_A, cnt_B, cnt_P = 0, 0, 0\n\n\t\tfeatures = pd.DataFrame(bert_output.loc[i,\"features\"]) # Get the BERT embeddings for the current line in the data file\n\t\tfor j in range(2,len(features)):  # Iterate over the BERT tokens for the current line; we skip over the first 2 tokens, which don't correspond to words\n\t\t\ttoken = features.loc[j,\"token\"]\n\n\t\t\t# See if the character count until the current token matches the offset of any of the 3 target words\n\t\t\tif count_chars  == P_offset: \n\t\t\t\t# print(token)\n\t\t\t\temb_P += np.array(features.loc[j,\"layers\"][0]['values'])\n\t\t\t\tcnt_P += 1\n\t\t\tif count_chars in range(A_offset, A_offset + A_length): \n\t\t\t\t# print(token)\n\t\t\t\temb_A += np.array(features.loc[j,\"layers\"][0]['values'])\n\t\t\t\tcnt_A +=1\n\t\t\tif count_chars in range(B_offset, B_offset + B_length): \n\t\t\t\t# print(token)\n\t\t\t\temb_B += np.array(features.loc[j,\"layers\"][0]['values'])\n\t\t\t\tcnt_B +=1\t\t\t\t\t\t\t\t\n\t\t\t# Update the character count\n\t\t\tcount_chars += count_length_no_special(token)\n\t\t# Taking the average between tokens in the span of A or B, so divide the current value by the count\t\n\t\temb_A /= cnt_A\n\t\temb_B /= cnt_B\n\n# \t\t# Work out the label of the current piece of text\n# \t\tlabel = \"Neither\"\n# \t\tif (data.loc[i,\"A-coref\"] == True):\n# \t\t\tlabel = \"A\"\n# \t\tif (data.loc[i,\"B-coref\"] == True):\n# \t\t\tlabel = \"B\"\n\n\t\t# Put everything together in emb\n\t\temb.iloc[i] = [emb_A, emb_B, emb_P]\n\n\treturn emb","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Loading the trained logistic regression's weights","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"loaded_model = pickle.load(open('../input/final257/finalized_model.sav', 'rb'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"flag = 0\nfor m in range(0,12360,200):\n    test_embed = run_bertpred(test_data[m,m+200].reset_index())\n    X_test = featurizepred(test_embed.sort_index().reset_index())\n    X_test = my_imputer.fit_transform(X_test)\n    logit_test_pred = loaded_model.predict_proba(X_test)\n    for n in range(200):\n        submission.iloc[flag+n][\"A\"] = logit_test_pred[n,0]\n        submission.iloc[flag+n][\"B\"] = logit_test_pred[n,1]\n        submission.iloc[flag+n][\"NEITHER\"] = logit_test_pred[n,2]\n    flag+=200\n    print(flag)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"finally getting the submittable csv file","execution_count":null},{"metadata":{"trusted":true},"cell_type":"code","source":"submission.to_csv(\"/kaggle/working/submissionfinnale.csv\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}